{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f0dd85",
   "metadata": {},
   "source": [
    "# Chapter 4 - The BERT algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7f58e",
   "metadata": {},
   "source": [
    "2022 February 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d8ba1",
   "metadata": {},
   "source": [
    "![bande](img/bande.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a599875",
   "metadata": {},
   "source": [
    "[... but don't forget about Ernie!](https://www.sesamestreet.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc3084",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "We will walkthrough the tensorflow \"Classisfy Text with BERT\" tutorial for this session: https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "Be sure to go through the below tutorials at some point, since they will help you better contextualize what is happening in the BERT tutorial:\n",
    "1. basic text classification: https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "2. word embeddings: https://www.tensorflow.org/text/guide/word_embeddings\n",
    "3. word2vec: https://www.tensorflow.org/tutorials/text/word2vec\n",
    "\n",
    "<h1 style=\"font-size: 4rem; color: #8C1515\">Access the notebooks</h1>\n",
    "\n",
    "**It is strongly recommeneded that you download the notebooks (or setup your Colab environment) in advance of our meeting session.** \n",
    "\n",
    "> NOTE: the datasets used in these notebooks are too large to host on GitHub, thus you need to download them separately.\n",
    "\n",
    "At the top of each tutorial page, click the appropriate button to access the notebooks.\n",
    "\n",
    "![tfdl](img/tfdl.png)\n",
    "\n",
    "<h1 style=\"font-size: 4rem; color: #00505C\">Run all code</h1>\n",
    "\n",
    "**Also be sure to run all code in advance.**\n",
    "\n",
    "The models will likely take 1-2 hours to fit and we will not have time to do so during the walkthrough. \n",
    "\n",
    "<h1 style=\"font-size: 4rem; color: #2ecc71\">Need help?</h1>\n",
    "\n",
    "Contact muzzall {at} stanford {dot} edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f2515",
   "metadata": {},
   "source": [
    "## Setup and software library installation instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cac90",
   "metadata": {},
   "source": [
    "### Install tensorflow\n",
    "\n",
    "If the instructions in the tensorflow \"Classify Text with Bert\" notebook do not work, try the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244f367",
   "metadata": {},
   "source": [
    "Or, setup a virtual environment (you might find this more complicated, but it is worth it in the long run). \n",
    "\n",
    "View the instructions: https://www.tensorflow.org/install/pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9549e",
   "metadata": {},
   "source": [
    "### A dependency of the preprocessing for BERT inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U tensorflow-text==2.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f04da",
   "metadata": {},
   "source": [
    "### AdamW optimizer\n",
    "\n",
    "Use the AdamW optimizer from tensorflow/models: https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U tensorflow-text==2.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dc3b3",
   "metadata": {},
   "source": [
    "### Install pydot and graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51566cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pydot\n",
    "# !pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf9886",
   "metadata": {},
   "source": [
    "graphviz installation instructions: https://graphviz.org/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b352f",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c32fbe",
   "metadata": {},
   "source": [
    "![accloss](img/accloss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30db592",
   "metadata": {},
   "source": [
    "![weboard](img/weboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a97d28",
   "metadata": {},
   "source": [
    "## Semantic similarity\n",
    "\n",
    "See \"Application Examples\" section here: https://github.com/UKPLab/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f227b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca81f5",
   "metadata": {},
   "source": [
    "### Find pairs of sentences with highest cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5a1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6788\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5096\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2560\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2440\n",
      "A man is playing guitar \t\t The cat plays in the garden \t\t Score: 0.2105\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1969\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1692\n",
      "The cat sits outside \t\t A woman watches TV \t\t Score: 0.1310\n",
      "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0900\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Single list of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "#Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
