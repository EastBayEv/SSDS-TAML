{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - New Developments: Topic Modeling with BERTopic! \n",
    "\n",
    "2022 July 30\n",
    "\n",
    "![bertopic](img/bert_topic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is BERTopic? \n",
    "* As part of NLP analysis, it's likely that at some point you will be asked, \"What topics are most common in these documents?\"  \n",
    "\n",
    "    * Though related, this question is definitely distinct from a query like \"What words or phrases are most common in this corpus?\" \n",
    "\n",
    "        * For example, the sentences \"I enjoy learning to code.\" and \"Educating myself on new computer programming techniques makes me happy!\" contain wholly unique tokens, but encode a similar sentiment. \n",
    "\n",
    "        * If possible, we would like to extract *generalized topics* instead of specific words/phrases to get an idea of what a document is about. \n",
    "\n",
    "* This is where BERTopic comes in! BERTopic is a cutting-edge methodology that leverages the transformers defining the base BERT technique along with other ML tools to provide a flexible and powerful topic modeling module (with great visualization support as well!)\n",
    "\n",
    "* In this notebook, we'll go through the operation of BERTopic's key functionalities and present resources for further exploration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required installs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bertopic in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (0.9.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (1.21.5)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (0.5.2)\n",
      "Requirement already satisfied: pyyaml<6.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (5.4.1)\n",
      "Requirement already satisfied: hdbscan>=0.8.27 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (0.8.27)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (1.1.1)\n",
      "Requirement already satisfied: plotly<4.14.3,>=4.7.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (4.14.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from bertopic) (1.4.3)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from hdbscan>=0.8.27->bertopic) (1.1.0)\n",
      "Requirement already satisfied: cython>=0.27 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from hdbscan>=0.8.27->bertopic) (0.29.30)\n",
      "Requirement already satisfied: six in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from hdbscan>=0.8.27->bertopic) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from hdbscan>=0.8.27->bertopic) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from plotly<4.14.3,>=4.7.0->bertopic) (1.3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.12.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\n",
      "Requirement already satisfied: nltk in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.5)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (61.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (4.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: sacremoses in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.10.3)\n",
      "Requirement already satisfied: filelock in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: click in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/evanmuzzall/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mzsh:1: no matches found: bertopic[flair]\n",
      "zsh:1: no matches found: bertopic[visualization]\n"
     ]
    }
   ],
   "source": [
    "# Installs the base bertopic module:\n",
    "!pip install bertopic \n",
    "\n",
    "# If you want to use other transformers/language backends, it may require additional installs: \n",
    "!pip install bertopic[flair] # can substitute 'flair' with 'gensim', 'spacy', 'use'\n",
    "\n",
    "# bertopic also comes with its own handy visualization suite: \n",
    "!pip install bertopic[visualization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sourcing \n",
    "\n",
    "* For this exercise, we're going to use a popular data set, '20 Newsgroups,' which contains ~18,000 newsgroups posts on 20 topics. This dataset is readily available to us through Scikit-Learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bertopic\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "documents = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "print(documents[0]) # Any ice hockey fans? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a BERTopic model: \n",
    "\n",
    "* Using the BERTopic module requires you to fetch an instance of the model. When doing so, you can specify multiple different parameters including: \n",
    "    * ```language``` -> the language of your documents\n",
    "    * ```min_topic_size``` -> the minimum size of a topic; increasing this value will lead to a lower number of topics \n",
    "    * ```embedding_model``` -> what model you want to use to conduct your word embeddings; many are supported!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a full list of the parameters and their significance, please see https://github.com/MaartenGr/BERTopic/blob/master/bertopic/_bertopic.py. \n",
    "\n",
    "* Of course, you can always use the default parameter values and instantiate your model as ```model = BERTopic()```. Once you've done so, you're ready to fit your model to your documents! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Example instantiation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# example parameter: a custom vectorizer model can be used to remove stopwords from the documents: \n",
    "stopwords_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n",
    "\n",
    "# instantiating the model: \n",
    "model = BERTopic(vectorizer_model = stopwords_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model: \n",
    "\n",
    "* The first step of topic modeling is to fit the model to the documents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topics, probs = model.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```.fit_transform()``` returns two outputs:\n",
    "    \n",
    "    * ```topics``` contains mappings of inputs (documents) to their modeled topic (alternatively, cluster)\n",
    "    \n",
    "    * ```probs``` contains a list of probabilities that an input belongs to their assigned topic \n",
    "\n",
    "* **Note:** ```fit_transform()``` can be substituted with ```fit()```. ```fit_transform()``` allows for the prediction of new documents but demands additional computing power/time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing topic modeling results: \n",
    "\n",
    "* The BERTopic module has many built-in methods to view and analyze your fitted model topics. Here are some basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view your topics: \n",
    "topics_info = model.get_topic_info()\n",
    "\n",
    "# get detailed information about the top five most common topics: \n",
    "print(topics_info.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When examining topic information, you may see a topic with the assigned number '-1.' Topic -1 refers to all input outliers which do not have a topic assigned and should typically be ignored during analysis. \n",
    "\n",
    "* Forcing documents into a topic could decrease the quality of the topics generated, so it's usually a good idea to allow the model to discard inputs into this 'Topic -1' bin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a single topic: \n",
    "print(model.get_topic(topic=0)) # .get_topics() accesses all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get representative documents for a specific topic: \n",
    "print(model.get_representative_docs(topic=0)) # omit the 'topic' parameter to get docs for all topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find topics similar to a key term/phrase: \n",
    "topics, similarity_scores = model.find_topics(\"sports\", top_n = 5)\n",
    "print(\"Most common topics:\" + str(topics)) # view the numbers of the top-5 most similar topics\n",
    "\n",
    "# print the initial contents of the most similar topics\n",
    "for topic_num in topics: \n",
    "    print('\\nContents from topic number: '+ str(topic_num) + '\\n')\n",
    "    print(model.get_topic(topic_num))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/loading models: \n",
    "* One of the most obvious drawbacks of using the BERTopic technique is the algorithm's run-time. But, rather than re-running a script every time you want to conduct topic modeling analysis, you can simply save/load models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model: \n",
    "# model.save(\"TAML_ex_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it later: \n",
    "# loaded_model = BERTopic.load(\"TAML_ex_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing topics:\n",
    "* Although the prior methods can be used to manually examine the textual contents of topics, visualizations can be an excellent way to succinctly communicate the same information. \n",
    "\n",
    "* Depending on the visualization, it can even reveal patterns that would be much harder/impossible to see through textual analysis - like inter-topic distance! \n",
    "\n",
    "* Let's see some examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D representation of your modeled topics & their pairwise distances: \n",
    "model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the words and probabilities of top topics, but in bar chart form! \n",
    "model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate topic similarity through a heat map: \n",
    "model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "* Hopefully you're convinced of how accessible but powerful a technique BERTopic topic modeling can be! There's plenty more to learn about BERTopic than what we've covered here, but you should be ready to get started! \n",
    "\n",
    "* During your adventures, you may find the following resources useful: \n",
    "    * *Original BERTopic Github:* https://github.com/MaartenGr/BERTopic\n",
    "\n",
    "    * *BERTopic visualization guide:* https://maartengr.github.io/BERTopic/getting_started/visualization/visualization.html#visualize-terms\n",
    "    \n",
    "    * *How to use BERT to make a custom topic model:* https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "* Recommended things to look into next include: \n",
    "    - how to select the best embedding model for your BERTopic model; \n",
    "\n",
    "    - controlling the number of topics your model generates; and \n",
    "\n",
    "    - other visualizations and deciding which ones are best for what kinds of documents. \n",
    "\n",
    "* Questions? Please reach out! Anthony Weng, SSDS consultant, is happy to help (contact: ad2weng@stanford.edu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "16c684165a00eba53f696e92e1de76bb4a10a33402bb31cdf5ab4f07210fc261"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
